#! /usr/bin/env bash

: <<=cut
=pod

=head1  NAME

harvest - overall harvest command

=head1 SYNOPSIS

harvest [-b|--base=<base>]
  <command> [<args>]

  where <command> is one of xslt


=head1 GLOBAL OPTIONS

=over 4

=item B<-b|--base = directory>

Specify the base directory for your feed results. Default C<base=./>.


=item B<-v|--verbose>

Log some of the commands that your are going to run.

=item B<-h|--help>

Shows the manpage for the program. The help pages are embedded in the script and
require the functions, C<pod2usage> and C<pod2text> to work properly.

=back

=cut

function main.init() {

  #MAIN
    # global Variables
    declare -g -A G=(
      [harvest_home]="$( cd "$( dirname "${BASH_SOURCE[0]}" )/../lib/harvest" >/dev/null 2>&1 && pwd )"
      [iam_api_endpoint]="iam.api:=https://iet-ws.ucdavis.edu/api/iam"
      [iam_search]=""
      [fuseki_host]='http://fuseki:3030'
      [harvest_db]=''
      [fuseki_admin]='http://fuseki:8080'
      [fuseki_user]='admin'
      [fuseki_password]=''
      [fuseki_auth]=''
      [util_getopt]=${HARVEST_UTIL_GETOPT:-${FLAGS_GETOPT_CMD:-getopt}}
    );

    local opts;
    if ! opts=$(${G[util_getopt]} -o f:b:vh --long db:,fuseki-host:,fuseki-auth:,base:,verbose,help -n 'harvest' -- "$@"); then
    echo "Bad Command Options." >&2 ; exit 1 ; fi

    eval set -- "$opts"

    local i
    declare -A CMD;
    while true; do
	    case $1 in
	      -b | --base) CMD[base]=$2;  shift 2;;
	      -f | --fuseki-host) CMD[fuseki_host]=$2;  shift 2;;
	      -d | --db) CMD[harvest_db]=$2;  shift 2;;
	      --fuseki-admin) CMD[fuseki_admin]=$2;  shift 2;;
	      -a | --fuseki-auth) CMD[fuseki_auth]=$2;  shift 2;;
	      -v | --verbose) CMD[verbose]=1;  shift;;
        -h | --help ) exec pod2text $0;;
	      -- ) shift; break;;
	      *) shift; break;
      esac
    done

    # system variables (ELEMENTS_FOO_BAR) over config file
    # the HARVEST command uses root variables for these input, that is, eg
    # FUSEKI_PASSWORD, etc.
    for i in "${!G[@]}"; do
      eval v=\$${i^^}
      [[ -n $v ]] && G[$i]=$v
    done

    # command line over config and over system var
    for i in "${!CMD[@]}"; do
      [[ -n ${CMD[$i]} ]] && G[$i]=${CMD[$i]};
    done

    # Now build an auth if needed
    [[ -n ${G[fuseki_auth]} ]] || G[fuseki_auth]="${G[fuseki_user]}:${G[fuseki_password]}"

}

: <<='cut'

=pod

=head1 COMMANDS

Next there are a set of commands that communicate with the CDL service. Note,
that ezid uses L<httpie|https://httpie.org/> for its http communcation. This
allows users to combine ezid with other httpie requests if required. Login
infomation is stored using the standard C<httpie> methodology, see L</"GLOBAL OPTIONS"> for httpid options.

C<elements [options] harvest --full> Harvests a number of feeds from the
Elements database and stores each record in a separate file.  This is to match how
the Sympletic Harvester works

=cut

function main.cmd () {
    cmd=$1
    shift;
    case $cmd in
	    xslt) # VIVO Harvester
	      $cmd "$@";
	      ;;
      db | load | fuseki | update | query ) # Fuseki commands
        $cmd "$@";
        ;;
      config ) # informational requests
        _${cmd} "$@";
        ;;
	    *)
	      exec pod2usage $0
	  ;;
    esac
}

function log() {
  [[ -n ${G[verbose]} ]] && (>&2 echo LOG: $@)
}

function err() {
  local n=1;
  if [[ $1 = '--quiet' ]] ; then
    n=$2;
  else
    n=$1
    shift
    (>&2 echo err: $@)
  fi
  exit $n;
}

: <<='cut'
=pod

=head2 COMMAND

harvest I<options> B<db> list|rm|new [service]

Performs processes on the fuseki instance.  These are command-line overlays to
the harvetstdb admin API in the ucd-rp-fuseki host.


=head3 COMMANDS

=over 4

=item B<list>

List all fuseki harvest services.  The list comes from the existing harvest
databases, not the services running in the server.

=item B<new> [service]

Add a new harvest service.  This will add a standard database, with a private
section, as well as access to the public data.

=item B<rm> [service]

Delete a harvest service.  This will remove the configuration, and the
underlying database file.  This takes advantage of the L<fuseki HTTP adminsration protocol|https://jena.apache.org/documentation/fuseki2/fuseki-server-protocol.html>

=back

=cut

function db() {
  local cmd

  local auth=${G[fuseki_auth]}
  local dbs=()

  cmd=$1
  shift;

  case $cmd in
    datasets)
      http --print=b --auth=${auth} GET ${G[fuseki_host]}/\$/datasets | jq '.datasets[]["ds.name"]'
      ;;
    list)
      http --print=b --auth=${auth} GET ${G[fuseki_admin]}/harvestdb
      ;;
    rm)
      while [[ -n "$1" ]]; do
        dbs+=$(http --auth=${auth} DELETE ${G[fuseki_admin]}/harvestdb?name=$1)
        shift
      done
      ;;
    new)
      if [[ -z "$1" ]]; then
        dbs+=$(http --auth=${auth} POST ${G[fuseki_admin]}/harvestdb)
      else
        while [[ -n "$1" ]]; do
          dbs+=$(http --auth=${auth} POST ${G[fuseki_admin]} /harvestdb?name=$1)
          shift
        done
      fi
      ;;
    *) err "Invalid command $cmd"
       ;;
  esac
  echo "${dbs[@]}"
}


: <<='cut'
=pod

=head2 COMMAND

harvest I<global_options> B<query> I<options> file1.ttl file2.ttl ...

Run update queries on the fuseki harvestdb endpoint.  I

=cut

function update () {
  local file;
  if [[ -n ${G[harvest_db]} ]]; then
    local auth=${G[fuseki_auth]}
    local update=${G[fuseki_host]}/${G[harvest_db]}/update

    log ${update}
    # Short hand for files in lib/harvest
    for file in "$@"; do
      [[ "$file" = '-' ]] && file=/dev/stdin
      if [[ ! -f $file ]]; then
        file=${G[harvest_home]}/rq/$file;
        [[ -f $file ]] || file=${file}.ru
      fi
      if [[ -f $file ]]; then
        log "curl -i --location --request POST --user \"${auth}\" -H Content-Type:application/sparql-update --data-binary \"@${file}\" ${update}"
        curl -i --location --request POST --user "${auth}" -H Content-Type:application/sparql-update --data-binary "@${file}" ${update}
      else
        log $file not found
      fi
    done
  else
    log "No harvest-db specified, via --db= or via HARVEST_DB env. variable."
  fi
}


: <<='cut'
=pod

=head2 COMMAND

harvest I<global_options> B<update> I<options> file1.ttl file2.ttl ...

Run update queries on the fuseki harvestdb endpoint.  I

=cut

function update () {
  local file;
  if [[ -n ${G[harvest_db]} ]]; then
    local auth=${G[fuseki_auth]}
    local update=${G[fuseki_host]}/${G[harvest_db]}/update

    log ${update}
    # Short hand for files in lib/harvest
    for file in "$@"; do
      [[ "$file" = '-' ]] && file=/dev/stdin
      if [[ ! -f $file ]]; then
        file=${G[harvest_home]}/rq/$file;
        [[ -f $file ]] || file=${file}.ru
      fi
      if [[ -f $file ]]; then
        log "curl -i --location --request POST --user \"${auth}\" -H Content-Type:application/sparql-update --data-binary \"@${file}\" ${update}"
        curl -i --location --request POST --user "${auth}" -H Content-Type:application/sparql-update --data-binary "@${file}" ${update}
      else
        log $file not found
      fi
    done
  else
    log "No harvest-db specified, via --db= or via HARVEST_DB env. variable."
  fi
}

: <<='cut'
=pod

=head2 COMMAND

harvest I<options> B<load> files

Use http to load our data files into the harvestdb.  The harvestdb is specified
as a global environment.

=head3 load OPTIONS

=over 4

=item B<--graph=I<graph_url>>

Select the graph to insert the data.

=item B<--suffix=I<ttl|jsonld>>

if you include stdin, specify the filename suffix to use, eg. C<--suffix=ttl>
will identify C<stdin> as C<file.ttl>.  This can help the data endpoint to
understand the format.  =back

=back

=cut

function load () {
  local opts;
  if ! opts=$(${G[util_getopt]} -o g:f: --long graph:,format: -n 'harvest load' -- "$@"); then
    echo "Bad Command Options." >&2 ; exit 1 ; fi

  eval set -- "$opts"

  declare -A CMD=(
    [graph]="http://experts.ucdavis.edu/nograph/"
    [suffix]="ttl"
    );

  while true; do
	  case $1 in
	    -g | --graph) CMD[graph]=$2;  shift 2;;
	    -s | --suffix) CMD[suffix]=$2;  shift 2;;
	    -- ) shift; break;;
	    *) shift; break;
    esac
  done

  local file;
  if [[ -n ${G[harvest_db]} ]]; then
    local auth=${G[fuseki_auth]}
    local load=${G[fuseki_host]}/${G[harvest_db]}/data

    for file in "$@"; do
      if [[ "$file" = '-' ]]; then
        file=/dev/stdin
        fn=file.${CMD[suffix]}
      else
        fn=$file
      fi
      log "curl --location --request POST --user ${auth} -H \"Content-Type:multipart/form-data\" -F \"file=@${file};filename=${fn}\" \"${load}?graph=${CMD[graph]}\""
      curl --location --request POST --user ${auth} -H "Content-Type:multipart/form-data" -F "file=@${file};filename=${fn}" "${load}?graph=${CMD[graph]}"
    done
  fi
  # No can load both
  if [[ -n ${G[tdb]} ]]; then
    for file in "$@"; do
      [[ "$file" = '-' ]] && file=/dev/stdin
      log "tdb2.tdbloader --loc=${G[tdb]} --graph=${G[graph]} $file"
      tdb2.tdbloader --loc=${G[tdb]} --graph=${G[graph]} $file
    done
  fi
}

<<='cut'
=pod

=head2 COMMAND

harvest I<options> B<xslt> []

Runs the old VIVO_Harvester processing. This B<only> runs in /usr/local/vivo/harvester/data

=head3 xslt OPTIONS

=over 4

=item B<--select=I<filename>>

After processing, run a select on the TDB database, and save to the file.

=back

=cut

function xslt() {
  local opts;
  if ! opts=$(${G[util_getopt]} -o nrs: --long no-reprocess,reprocess,select: -n 'xslt' -- "$@"); then
    echo "Bad Command Options." >&2 ; exit 1 ; fi

  eval set -- "$opts"

  local select
  local reprocess=1
  local d=/usr/local/vivo/harvester
  local update="tdbupdate --loc=${d}/data/tdb-output/1 --update=-"
  local query="tdbquery --loc=${d}/data/tdb-output/1 --query=-"

  while true; do
	  case $1 in
	    -r | --reprocess) reprocess=1;  shift 2;;
	    -n | --no-reprocess) reprocess='';  shift 2;;
	    -s | --select) select=$2;  shift 2;;
	    -- ) shift; break;;
	    *) shift; break;
    esac
  done

  function initialize_state_txt() {
    echo '0'
    date --utc --iso-8601=sec | sed -e 's/\+00:00/+0000/'
    echo '0'
  }

  if [[ -n $reprocess ]]; then
    initialize_state_txt > $d/data/state.txt
    rm -rf ${d}/data/tdb-output
	  if ! ${d}/elementsfetch.sh --reprocess; then
      err "elementsfetch failed"
    fi
  fi

  if [[ -n $select ]]; then
	  ${update} <<<'delete WHERE {?s ?p <http://experts.ucdavis.edu/ontology/local#InternalClass>. }'
	  ${update} <<<'PREFIX vivo: <http://vivoweb.org/ontology/core#> delete {?s ?p ?o. } WHERE {VALUES (?d) {(vivo:University)(vivo:AcademicDepartment)} ?s a ?d ;?p ?o .}'
	  ${query} <<<'construct {?s ?p ?o. } WHERE {?s ?p ?o .}' > ${select}
  fi

}

: <<='cut'
=pod

=head1 DEPENDANCIES

Elements uses a number of external bash commands. These must be installed for
the elements script to work.

=over 4

=item L<httpie|https://httpie.org/>

httpie is a command-line tool similar to B<curl>. Since we only really need the
authentication, it may be better to use curl here and the .netrc file instead.
It is nice to have the httpie interface however, for debugging.

=item L<getopt>

${FLAGS_GETOPT_CMD:-getopt}

=back

=head1 AUTHOR

Quinn Hart <qjhart@ucdavis.edu>

=cut


OPTS=();
while true; do
	case $1 in
	  -*) OPTS+=($1); shift ;;
	  -- ) shift; break;;
	  *) break;
	esac
done

main.init "${OPTS[@]}"
main.cmd "$@"

exit 0;
