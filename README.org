* Harvesting Notes
:PROPERTIES:
:header-args:http: :host http://localhost:3030 :user admin:quinnisgreat
:header-args:sparqlx: :url http://sparql.org/sparql :format text/csv
:header-args:sparql: :url http://localhost:3030/experts_private/sparql :format text/csv
:END:

** Manual Updates to the rc database

#+BEGIN_SRC bash
dc pull
dc down
update .env for testing
dc up -d

# Just fetch the experts graph.
experts_git=gitlab.dams.library.ucdavis.edu/experts/experts-data.git
docker-compose exec fuseki fuseki-import-graphs \
--clone="https://quinn:${GITLAB_PUSH_TOKEN}@${experts_git} \
--single-branch --branch=experts-dev" --graph=experts.ucdavis.edu

# Get users from other setup
src=http://gold.experts.library.ucdavis.edu:3005/experts/query
q='PREFIX : <http://experts.ucdavis.edu/schema#> select ?userId WHERE { [] a :person; :casId ?userId} order by ?userId'

users=$(http --print=b --follow ${src} query=="$q" Accept:text/csv | tail -n+2 | tr -s '\n\r' ' ')

dc exec harvest harvest -v login

for id in $users; do dc exec harvest harvest -v user --search=userId=$id --init --remove; done

# We have to make a special change for Kim, Sangtae
db=$(dc exec harvest harvest db new)
http --auth=admin:quinnisgreat http://localhost:8081/${db}/update Content-type:application/sparql-update <<<'
PREFIX experts_iam: <http://experts.ucdavis.edu/iam/>
PREFIX person: <http://experts.ucdavis.edu/person/>
PREFIX vivo: <http://vivoweb.org/ontology/core#>
delete { graph experts_iam: {person:1b9f745893ea8c821a3fc847e9775dbe a vivo:NonAcademic. } }
insert { graph experts_iam: {person:1b9f745893ea8c821a3fc847e9775dbe a vivo:FacultyMember. } }
WHERE {}'

dc exec harvest harvest rm $db

#+END_SRC

#+RESULTS:
: Email bug reports to:  bug-dc@gnu.org .

*** Exporting data

One you have all the data installed, you may like to

#+BEGIN_SRC bash
dc exec harvest harvest export
#+END_SRC

#+BEGIN_SRC bash
branch=experts-dev
cd ~/experts-data
git checkout $branch
p=rp-ucd-deployment_harvest_1:/var/lib/harvest/export
docker cp $p/experts.ucdavis.edu%2Fiam/graph.ttl.gz  experts/experts.ucdavis.edu%2Fiam
gzip -d -f experts/experts.ucdavis.edu%2Fiam/graph.ttl.gz
docker cp $p/experts.ucdavis.edu%2Foap/graph.ttl.gz  experts/experts.ucdavis.edu%2Foap
#+END_SRC


*** Mulitple Users

You time the extent with 2 or three users by doing:


dc exec harvest harvest -v user --search=userId=quinn
dc exec harvest harvest -v user --search=userId=jrmerz

dc exec harvest harvest -v user --search=userId=quinn,jrmerz

#! /bin/make
users:=quinn jrmerz vensburg benthem

finished:=$(patsubst %,%.out ${users})   # finshe:=quinn.out jrmerz.out...

all:${finished}

${finished}:%.out
   time $(dc exec harvest harvest -v user --search=userId=$* --init --remove >
   $@) > $*.time



$> make -j 5 all 2





** Older Issues
*** Example Testing Script


#+BEGIN_SRC bash

# Login to the CDL database (one time)
# Logs in using CDL_AUTH and UCDID_AUTH
dc exec harvest harvest login

userIds="benthem chmkim jcgib jkmason mleite ramram rhcastro rkukreja sbsen sjmccorm spgentry sshong ytakamur"
for id in $userIds; do
  dc exec harvest harvest -v run --search=userId=$id --init --remove
done

# BAE Senate
emails="mahamed@ucdavis.edu gbornhorst@ucdavis.edu adaccache@ucdavis.edu jdemourabell@ucdavis.edu jmearles@ucdavis.edu jzfan@ucdavis.edu fathallah@ucdavis.edu megrismer@ucdavis.edu ylhsieh@ucdavis.edu bmjenkins@ucdavis.edu tjeoh@ucdavis.edu ikisekka@ucdavis.edu amoghimi@ucdavis.edu jsmullin@ucdavis.edu nnitin@ucdavis.edu npan@ucdavis.edu dcs@ucdavis.edu gysun@ucdavis.edu svougioukas@ucdavis.edu rhzhang@ucdavis.edu"
for id in $emails; do
  dc exec harvest harvest -v run --search=email=$id --init --remove
done

# BAE Federation
emails="irdonisgon@ucdavis.edu jdfernandezbayo@ucdavis.edu dafrank@ucdavis.edu thung@ucdavis.edu fkhorsandi@ucdavis.edu kkorn@ucdavis.edu palarbi@ucdavis.edu zlpan@ucdavis.edu apourreza@ucdavis.edu hbscher@ucdavis.edu jsvander@ucdavis.edu"
for id in $emails; do
  dc exec harvest harvest -v run --search=email=$id --init --remove
done

#+END_SRC


*** Comparisons to the Elements Harvester command

The harvest command will also run the XSLT processing from the sympletic
harvester.  This might be used to compare previous VIVO pulls.

#+BEGIN_SRC bash

export ELEMENTS_BASE=/usr/local/vivo/harvester/data
mkdir -p $ELEMENTS_BASE/raw-records

# The ids (for now) require that you've run the CDL step above.
ids=$(aeq --endpoint=${HARVEST_ENDPOINT}/sparql query --format=json <<<"select ?id where { graph harvest_oap: {?s oap:category 'user' . bind(replace(str(?s),str(harvest_oap:),'') as ?id) filter(isiri(?s))}} order by ?id" | jq -r .results.bindings[].id.value | tr [:space:] ' ')
export ELEMENTS_IDS=${ids// /,}

elements feed groups users user-relationships publications relationships
# There is a problem currently w/ groups, you need to
cp $ELEMENTS_BASE/feed/groups.xml $ELEMENTS_BASE/feed/groups.000

elements feed.split groups users publications relationships

# Now create data w/ xslt
harvest xslt --select=oapolicy.ttl

# And load it into db
harvest load --graph=http://experts.ucdavis.edu/oap/ oapolicy.ttl

# Save the graphs
for i in experts.ucdavis.edu%2Foap experts.ucdavis.edu%2Fiam
graph="http://"$(echo $i | sed -e 's|%2F|/|g')"/"
echo "aeq --endpoint=${HARVEST_ENDPOINT}/sparql query --format=ttl \<\<\<\"CONSTRUCT {?s ?p ?o } WHERE { graph <${graph}> { ?s ?p ?o.}}\" \> $i/graph.ttl"
end

#+END_SRC

#+RESULTS:
